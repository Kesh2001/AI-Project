{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"./MachineLearning.csv\")\n",
    "data['ref_date'] = pd.to_datetime(data['ref_date'])\n",
    "data.drop('predicted_vacancies', axis=1,inplace=True)\n",
    "data = data[data['ref_date'] >= '2019-01-01']  # Keep data from 2019 onwards\n",
    "\n",
    "# Sentiment mapping\n",
    "sentiment_mapping = {\n",
    "    2019: 1.826354,\n",
    "    2020: 1.826354,\n",
    "    2021: 0.930538,\n",
    "    2022: 0.000000,\n",
    "    2023: 0.000000,\n",
    "    2024: 0.568935\n",
    "}\n",
    "\n",
    "# Propagate sentiment scores forward for future years\n",
    "future_years = range(2025, 2027)\n",
    "for year in future_years:\n",
    "    sentiment_mapping[year] = 0.568935\n",
    "\n",
    "# Map sentiment scores to dataset\n",
    "data['sentiment_score'] = data['ref_date'].dt.year.map(sentiment_mapping)\n",
    "\n",
    "# Filter data for training until Q4 2022\n",
    "train_data = data[data['ref_date'] <= '2022-12-31']\n",
    "\n",
    "# Aggregate by geo, noc_code, noc_desc, ref_date, and job_char\n",
    "aggregated_data = (\n",
    "    train_data.groupby(['geo', 'noc_code', 'noc_desc', 'ref_date', 'job_char'])\n",
    "    [['total_vacancies']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "aggregated_data = aggregated_data[aggregated_data['geo'] != 'Northwest Territories']  # Remove unwanted regions\n",
    "\n",
    "# Prepare DataFrame to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Define SARIMAX model parameters\n",
    "order = (1, 0, 1)\n",
    "seasonal_order = (1, 1, 0, 4)\n",
    "\n",
    "# Iterate through unique combinations of geo, noc_code, noc_desc, and job_char\n",
    "for (geo, noc_code, noc_desc, job_char), group in aggregated_data.groupby(['geo', 'noc_code', 'noc_desc', 'job_char']):\n",
    "    # Ensure the time series is indexed by 'ref_date' and follows quarterly frequency\n",
    "    group = group.set_index('ref_date').asfreq('QS')\n",
    "\n",
    "    # Fill missing values\n",
    "    group['total_vacancies'] = group['total_vacancies'].fillna(0)\n",
    "\n",
    "    # Train SARIMAX model\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            group['total_vacancies'],  # Endogenous variable\n",
    "            order=order,\n",
    "            seasonal_order=seasonal_order,\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False,\n",
    "        )\n",
    "        results = model.fit(disp=0)\n",
    "\n",
    "        # Forecast from Q1 2023 to Q2 2026 (14 quarters)\n",
    "        forecast_steps = 14\n",
    "        forecast_dates = pd.date_range(start='2023-01-01', periods=forecast_steps, freq='QS')\n",
    "\n",
    "        # Map sentiment scores for forecasted years\n",
    "        forecast_sentiment = [sentiment_mapping[date.year] for date in forecast_dates]\n",
    "\n",
    "        forecast = results.get_forecast(steps=forecast_steps)\n",
    "        forecast_df = forecast.summary_frame()\n",
    "\n",
    "        # Prepare forecast DataFrame\n",
    "        forecast_df['geo'] = geo\n",
    "        forecast_df['noc_code'] = noc_code\n",
    "        forecast_df['noc_desc'] = noc_desc\n",
    "        forecast_df['job_char'] = job_char\n",
    "        forecast_df['ref_date'] = forecast_dates\n",
    "        forecast_df['sentiment_score'] = forecast_sentiment\n",
    "\n",
    "        # Append the relevant columns to predictions\n",
    "        predictions.append(forecast_df[['ref_date', 'geo', 'noc_code', 'noc_desc', 'job_char', 'sentiment_score', 'mean']])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing geo: {geo}, noc_code: {noc_code}, job_char: {job_char} - {e}\")\n",
    "\n",
    "# Combine predictions for all groups into a single DataFrame\n",
    "predictions_df = pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "# Rename the 'mean' column to 'predicted_total_vacancies'\n",
    "predictions_df.rename(columns={'mean': 'predicted_total_vacancies'}, inplace=True)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_df.to_csv('predictions_with_sentiment.csv', index=False)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Predictions saved to predictions_with_sentiment.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
