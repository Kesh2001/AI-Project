{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"./MachineLearning.csv\")\n",
    "data['ref_date'] = pd.to_datetime(data['ref_date'])\n",
    "data.drop('predicted_vacancies', axis=1,inplace=True)\n",
    "data = data[data['ref_date'] >= '2019-01-01']  # Keep data from 2019 onwards\n",
    "\n",
    "# Sentiment mapping\n",
    "sentiment_mapping = {\n",
    "    2019: 1.826354,\n",
    "    2020: 1.826354,\n",
    "    2021: 0.930538,\n",
    "    2022: 0.000000,\n",
    "    2023: 0.000000,\n",
    "    2024: 0.568935\n",
    "}\n",
    "\n",
    "# Propagate sentiment scores forward for future years\n",
    "future_years = range(2025, 2027)\n",
    "for year in future_years:\n",
    "    sentiment_mapping[year] = 0.568935\n",
    "\n",
    "# Map sentiment scores to dataset\n",
    "data['sentiment_score'] = data['ref_date'].dt.year.map(sentiment_mapping)\n",
    "\n",
    "# Filter data for training until Q4 2022\n",
    "train_data = data[data['ref_date'] <= '2022-12-31']\n",
    "\n",
    "# Aggregate by geo, noc_code, noc_desc, ref_date, and job_char\n",
    "aggregated_data = (\n",
    "    train_data.groupby(['geo', 'noc_code', 'noc_desc', 'ref_date', 'job_char'])\n",
    "    [['total_vacancies']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "aggregated_data = aggregated_data[aggregated_data['geo'] != 'Northwest Territories']  # Remove unwanted regions\n",
    "\n",
    "# Prepare DataFrame to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Define SARIMAX model parameters\n",
    "order = (1, 0, 1)\n",
    "seasonal_order = (1, 1, 0, 4)\n",
    "\n",
    "# Iterate through unique combinations of geo, noc_code, noc_desc, and job_char\n",
    "for (geo, noc_code, noc_desc, job_char), group in aggregated_data.groupby(['geo', 'noc_code', 'noc_desc', 'job_char']):\n",
    "    # Ensure the time series is indexed by 'ref_date' and follows quarterly frequency\n",
    "    group = group.set_index('ref_date').asfreq('QS')\n",
    "\n",
    "    # Fill missing values\n",
    "    group['total_vacancies'] = group['total_vacancies'].fillna(0)\n",
    "\n",
    "    # Train SARIMAX model\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            group['total_vacancies'],  # Endogenous variable\n",
    "            order=order,\n",
    "            seasonal_order=seasonal_order,\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False,\n",
    "        )\n",
    "        results = model.fit(disp=0)\n",
    "\n",
    "        # Forecast from Q1 2023 to Q2 2026 (14 quarters)\n",
    "        forecast_steps = 14\n",
    "        forecast_dates = pd.date_range(start='2023-01-01', periods=forecast_steps, freq='QS')\n",
    "\n",
    "        # Map sentiment scores for forecasted years\n",
    "        forecast_sentiment = [sentiment_mapping[date.year] for date in forecast_dates]\n",
    "\n",
    "        forecast = results.get_forecast(steps=forecast_steps)\n",
    "        forecast_df = forecast.summary_frame()\n",
    "\n",
    "        # Prepare forecast DataFrame\n",
    "        forecast_df['geo'] = geo\n",
    "        forecast_df['noc_code'] = noc_code\n",
    "        forecast_df['noc_desc'] = noc_desc\n",
    "        forecast_df['job_char'] = job_char\n",
    "        forecast_df['ref_date'] = forecast_dates\n",
    "        forecast_df['sentiment_score'] = forecast_sentiment\n",
    "\n",
    "        # Append the relevant columns to predictions\n",
    "        predictions.append(forecast_df[['ref_date', 'geo', 'noc_code', 'noc_desc', 'job_char', 'sentiment_score', 'mean']])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing geo: {geo}, noc_code: {noc_code}, job_char: {job_char} - {e}\")\n",
    "\n",
    "# Combine predictions for all groups into a single DataFrame\n",
    "predictions_df = pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "# Rename the 'mean' column to 'predicted_total_vacancies'\n",
    "predictions_df.rename(columns={'mean': 'predicted_total_vacancies'}, inplace=True)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_df.to_csv('predictions_with_sentiment.csv', index=False)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Predictions saved to predictions_with_sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Range:\n",
      " count        6.000000\n",
      "mean     27633.333333\n",
      "std       2215.072610\n",
      "min      24205.000000\n",
      "25%      26492.500000\n",
      "50%      27997.500000\n",
      "75%      28876.250000\n",
      "max      30440.000000\n",
      "Name: total_vacancies, dtype: float64\n",
      "Predicted Range:\n",
      " count        6.000000\n",
      "mean     43284.952006\n",
      "std       5726.753284\n",
      "min      35074.812153\n",
      "25%      39449.724904\n",
      "50%      44311.113175\n",
      "75%      47204.368001\n",
      "max      50014.625111\n",
      "Name: predicted_total_vacancies, dtype: float64\n",
      "Capped MAPE for filtered data: 56.75%\n",
      "MdAPE for filtered data: 49.25%\n",
      "Accuracy for filtered data: 43.25%\n",
      "RMSE for filtered data: 16750.77\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remove rows with missing predicted vacancies\n",
    "filtered_df = filtered_df.dropna(subset=['predicted_total_vacancies'])\n",
    "\n",
    "# Investigate ranges\n",
    "actual_range = filtered_df['total_vacancies'].describe()\n",
    "predicted_range = filtered_df['predicted_total_vacancies'].describe()\n",
    "print(\"Actual Range:\\n\", actual_range)\n",
    "print(\"Predicted Range:\\n\", predicted_range)\n",
    "\n",
    "# Recalculate percentage error (capping extreme errors at 100%)\n",
    "filtered_df['percentage_error'] = np.abs((filtered_df['total_vacancies'] - filtered_df['predicted_total_vacancies']) / filtered_df['total_vacancies']) * 100\n",
    "filtered_df['percentage_error'] = filtered_df['percentage_error'].clip(upper=100)\n",
    "\n",
    "# Calculate MAPE using capped errors\n",
    "mape_filtered = filtered_df['percentage_error'].mean()\n",
    "\n",
    "# Alternatively, use MdAPE (Median Absolute Percentage Error)\n",
    "mdape_filtered = filtered_df['percentage_error'].median()\n",
    "\n",
    "# Recalculate RMSE\n",
    "rmse_filtered = np.sqrt(mean_squared_error(\n",
    "    filtered_df['total_vacancies'],\n",
    "    filtered_df['predicted_total_vacancies']\n",
    "))\n",
    "\n",
    "# Recalculate accuracy\n",
    "accuracy_filtered = 100 - mape_filtered\n",
    "\n",
    "# Print Results\n",
    "print(f\"Capped MAPE for filtered data: {mape_filtered:.2f}%\")\n",
    "print(f\"MdAPE for filtered data: {mdape_filtered:.2f}%\")\n",
    "print(f\"Accuracy for filtered data: {accuracy_filtered:.2f}%\")\n",
    "print(f\"RMSE for filtered data: {rmse_filtered:.2f}\")\n",
    "\n",
    "# Optional: Save filtered_df for further investigation\n",
    "filtered_df.to_csv('filtered_predictions_analysis.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
